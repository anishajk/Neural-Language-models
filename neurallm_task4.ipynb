{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Yox0gG1DsF"
   },
   "source": [
    "Homework 5: Neural Language Models  (& ðŸŽƒ SpOoKy ðŸ‘» authors ðŸ§Ÿ data) - Task 4\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: Sarthak Kagliwal Anisha Kumari Kushwaha (Write these in every notebook you submit. For each partner, write down whether you are a 4120 or a 6120 student.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWlOU9k1DsQ"
   },
   "source": [
    "Task 4: Compare your generated sentences (15 points)\n",
    "----\n",
    "\n",
    "In this task, you'll analyze one of the files that you produced in Task 3. You'll need to compare against the corresponding file that we have provided for you that was generated from the vanilla n-gram language model.\n",
    "\n",
    "Choose *__one__* of the following two options.\n",
    "\n",
    "Option 1: Evaluate the generated words of *character*-based models\n",
    "---\n",
    "\n",
    "Your job for this option is to programmatically measure two things:\n",
    "1. the percentage of words produced by each model that are valid english words.\n",
    "2. the percentage of words produced by each model that are valid english words *and* were not seen at train time.\n",
    "\n",
    "For this task, a word is defined as \"characters between _ \" or \"characters between spaces\" (if you replaced your underscores with spaces when you printed out your new sentences).\n",
    "\n",
    "\n",
    "Make sure to turn in any necessary supporting files along with your submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/sarthak55k/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "/Users/sarthak55k/Documents/NLP_course/HW5/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# your imports here\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "english_words = set(words.words())\n",
    "tokenizer = nltk.word_tokenize\n",
    "import keras\n",
    "import random\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here!\n",
    "\n",
    "def generate_word_list(filename):\n",
    "    word_list = []\n",
    "    with open(filename, 'r') as file:\n",
    "        # Initialize an empty list to store the words\n",
    "        # Iterate through each line in the file\n",
    "        for line in file:\n",
    "            # Split the line into words based on spaces or other delimiters\n",
    "            # words = line.split()\n",
    "            words = tokenizer(line.lower())\n",
    "            \n",
    "            # Add the words to the word_list\n",
    "            word_list.extend(words)\n",
    "    return word_list\n",
    "\n",
    "\n",
    "# the percentage of words produced by each model that are valid english words.\n",
    "\n",
    "def valid_nonvalid(word_list):\n",
    "    valid_words = []\n",
    "    invalid_words = []\n",
    "    total_words = 0\n",
    "    for word in word_list:\n",
    "        if word.isalpha():\n",
    "            if word in english_words:\n",
    "\n",
    "                valid_words.append(word)\n",
    "            else:\n",
    "                invalid_words.append(word)\n",
    "    return valid_words,invalid_words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#the percentage of words produced by each model that are valid english words and were not seen at train time.\n",
    "def not_seen_words(valid_words,vocab):\n",
    "    valid_word_outside_train = []\n",
    "    for word in valid_words:\n",
    "        if word.isalpha():\n",
    "            if word not in vocab:\n",
    "                valid_word_outside_train.append(word)\n",
    "        \n",
    "    return valid_word_outside_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Vanilla model...\n",
      "percentage of words that are valid english words: 43.140291111799314\n",
      "percentage of words that are valid english words and were not seen at train time: 5.264787860018581\n",
      "\n",
      "Random 100 samples of invalid words:\n",
      " ['louddis', 'sto', 'ishe', 'pette', 'youghtly', 'whic', 'whe', 'handown', 'earmea', 'andieflethimor', 'univeret', 'ance', 'dusubjectishat', 'livere', 'combeethe', 'gand', 'ity', 'shadnigning', 'gle', 'ste', 'swovey', 'magover', 'inglibbiz', 'jought', 'coresch', 'mands', 'ang', 'wormighat', 'wasmaked', 'therproughtfutuoureems', 'ity', 'mins', 'sau', 'thathe', 'ordis', 'samind', 'beger', 'fantestain', 'thele', 'maind', 'smages', 'syme', 'hoaterd', 'ful', 'oritly', 'yourappeld', 'whis', 'adren', 'anot', 'thads', 'ares', 'dideveriestow', 'exhien', 'poin', 'thaded', 'bled', 'ande', 'thaveherecally', 'memblown', 'gened', 'por', 'ract', 'fieve', 'inis', 'atioutedo', 'warld', 'adis', 'hemoreauthe', 'becelf', 'astions', 'taines', 'youghts', 'thatingtheyes', 'itin', 'scruchfouldit', 'redgerand', 'oforld', 'fich', 'thoorthe', 'musight', 'anat', 'destainnet', 'wents', 'whiste', 'risfaras', 'anin', 'monly', 'cationly', 'ther', 'ong', 'ony', 'dester', 'goond', 'abough', 'laregrach', 'wasimay', 'wifty', 'vello', 'ance', 'consur']\n",
      "\n",
      "For NN model\n",
      "percentage of words that are valid english words: 25.241779497098648\n",
      "percentage of words that are valid english words and were not seen at train time: 5.319148936170213\n",
      "\n",
      "Random 100 samples of invalid words:\n",
      " ['mithompereate', 'migetice', 'ousiced', 'iddiattedid', 'wardiattanglity', 'alloved', 'ang', 'woused', 'talsol', 'arsened', 'thices', 'ithicalliscant', 'hille', 'havy', 'orterys', 'chindestalsourichowaystrumbithowees', 'maggithentonsiceste', 'sticia', 'ofts', 'oreased', 'talister', 'tallend', 'bodid', 'orm', 'mignigh', 'trentic', 'imped', 'movat', 'tric', 'bovoultends', 'toons', 'hang', 'wattath', 'ond', 'whem', 'handstaid', 'oug', 'tattedistent', 'alinded', 'havings', 'tronery', 'wommoread', 'stelige', 'ter', 'oren', 'senewer', 'stillencencindingly', 'toway', 'wholite', 'ingeted', 'ands', 'artichow', 'ords', 'aseliencedist', 'humbichom', 'toorm', 'magatel', 'als', 'sedit', 'whind', 'cliscoul', 'alloordiaredid', 'thiled', 'clis', 'iner', 'isellyst', 'tormadined', 'tard', 'ong', 'townsent', 'anglys', 'mes', 'townes', 'im', 'sed', 'thavid', 'orme', 'andessoulachadde', 'ande', 'angselfoulan', 'arst', 'im', 'seend', 'tooded', 'aliginewiscit', 'tenticiougcompecese', 'watelighal', 'tragner', 'filined', 'ime', 'oleasice', 'shistal', 'ounat', 'whate', 'tenchanconsent', 'wome', 'trenes', 'taird', 'tattan', 'hurity']\n"
     ]
    }
   ],
   "source": [
    "def getPercentage(filename):\n",
    "    embedding_model = './spooky_embedding_word.txt'\n",
    "    w2v_word_model = KeyedVectors.load_word2vec_format(embedding_model, binary=False)\n",
    "\n",
    "    word_vocab = list(w2v_word_model.key_to_index.keys())\n",
    "    \n",
    "    char_words_list = generate_word_list(filename)\n",
    "    char_word_list_len = len(char_words_list)\n",
    "    char_valid_words, char_invalid_words = valid_nonvalid(char_words_list)\n",
    "\n",
    "    percentage_valid_words_char = ((len(char_valid_words)+1)/(char_word_list_len+1))*100\n",
    "\n",
    "    char_valid_word_outside_train = not_seen_words(char_valid_words,word_vocab)\n",
    "    percentage_valid_words_outside_vocab_char = ((len(char_valid_word_outside_train)+1)/(char_word_list_len+1))*100\n",
    "\n",
    "    print(f'percentage of words that are valid english words: {percentage_valid_words_char}')\n",
    "    print(f'percentage of words that are valid english words and were not seen at train time: {percentage_valid_words_outside_vocab_char}')\n",
    "\n",
    "\n",
    "    print(f'\\nRandom 100 samples of invalid words:\\n {random.sample(char_invalid_words,100)}')\n",
    "\n",
    "nn_filename = 'char_sents.txt'\n",
    "vanilla_filename = './spooky_vanilla_3_char.txt'\n",
    "\n",
    "print('For Vanilla model...')\n",
    "getPercentage(vanilla_filename)\n",
    "\n",
    "print('\\nFor NN model')\n",
    "getPercentage(nn_filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How did you determine what a valid english word is? NLTK "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Gather the sequences of characters that are determined not to be words. Sampling at minimum 100 of these sequences, how many of them *should have* been counted as words in your opinion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n"
     ]
    }
   ],
   "source": [
    "# more code here, as needed!\n",
    "char_words_list_nn = generate_word_list(nn_filename)\n",
    "char_valid_words_nn, char_invalid_words_nn = valid_nonvalid(char_words_list_nn)\n",
    "print(len(char_valid_words_nn))\n",
    "char_words_list_vanilla = generate_word_list(vanilla_filename)\n",
    "char_valid_words_vanilla, char_invalid_words_vanilla = valid_nonvalid(char_words_list_vanilla)\n",
    "\n",
    "valid_model = ['neural']*len(char_valid_words_nn)+ ['sequence']*len(char_valid_words_vanilla)\n",
    "\n",
    "valid_seq = char_valid_words_nn+char_valid_words_vanilla\n",
    "\n",
    "data = {'model':valid_model,'sequence':valid_seq}\n",
    "df_valid = pd.DataFrame(data)\n",
    "df_valid.head()\n",
    "\n",
    "df_valid.to_csv('valid_words_lms.csv')\n",
    "\n",
    "\n",
    "invalid_model = ['neural']*len(char_invalid_words_nn)+ ['sequence']*len(char_invalid_words_vanilla)\n",
    "invalid_seq = char_invalid_words_nn+char_invalid_words_vanilla\n",
    "\n",
    "data = {'model':invalid_model,'sequence':invalid_seq}\n",
    "df_invalid = pd.DataFrame(data)\n",
    "df_invalid.head()\n",
    "\n",
    "df_invalid.to_csv('invalid_words_lms.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit two csv files alongside this notebook: `valid_words_lms.csv` and `invalid_words_lms.csv`. Both files should have __two__ columns: `model`, `sequence`. `model` will have the value `neural` or `vanilla`. `sequence` will be the corresponding sequence of characters. `valid_words_lms.csv` should contain all sequences from both models you determined to be valid words. `invalid_words_lms.csv` will have all sequences from both models you programatically determined to be invalid words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "316H0xSh1DsQ"
   },
   "source": [
    "Option 2: Evaluate the generated sentences of *word*-based models\n",
    "----\n",
    "\n",
    "Your job for this option is to measure the quality of your generated sentences for word-based models. For this option you *must* survey at least 3 people who are __not__ in this course. They need to speak and read the language that you are evaluating, but they need not be native speakers.\n",
    "\n",
    "You will evaluate the quality of the generated sentences in the following way:\n",
    "1. Generate 20 sentences from your neural model.\n",
    "2. Using the same level of n-gram, pair these sentences with provided sentences from the vanilla n-gram model.\n",
    "\n",
    "Next, build a survey. For each pair of (neural LM sentence, vanilla n-ngram LM sentence), you'll ask the survey taker two binary selection questions:\n",
    "1. which sentence is more grammatical?\n",
    "2. which sentence makes more sense, semantically (in meaning)?\n",
    "3. Which sentence do you prefer?\n",
    "\n",
    "\n",
    "Finally, you'll evaluate your survey results. Calculate the following:\n",
    "1. What percentage of neural vs. vanilla n-gram LM sentences were preferred, separated along each of the three dimensions?\n",
    "2. What is [Krippendorff's alpha](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha) for your survey data? \n",
    "\n",
    "You are welcome to use a pre-built python implmenetation of the Krippendorff's alpha calculation, such as [this one](https://pypi.org/project/krippendorff/). Krippendorff's alpha is one way to measure interannotator agreement â€” the extent to which your survey respondants agree with one another.\n",
    "\n",
    "You will submit your survey data alongside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your imports here\n",
    "\n",
    "# import krippendorff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wordembeddings_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05041e657fa0436a83611a3d2d345b99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cd0685004814c0d974a1d809e0e2b4f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b0dca775977048f38841afae3d906eb6",
      "value": "100%"
     }
    },
    "140057e9712f46af9ebf5825ef9b1390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05041e657fa0436a83611a3d2d345b99",
       "IPY_MODEL_a818afa6bb4f43c8b7e32a3c04f17211",
       "IPY_MODEL_72a47718e310461fbd61b312f7bf7cfe"
      ],
      "layout": "IPY_MODEL_488b55855d4d4ffc8af6d3d77aa3fdf8"
     }
    },
    "150adc7de7f54d63a215482e6a977067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b93060412f54083b6dd7b9203ae55d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cd0685004814c0d974a1d809e0e2b4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488b55855d4d4ffc8af6d3d77aa3fdf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a47718e310461fbd61b312f7bf7cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d9e5b3a1e144e6b34a55ab5cbce43f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_150adc7de7f54d63a215482e6a977067",
      "value": " 19579/19579 [00:00&lt;00:00, 18295.70it/s]"
     }
    },
    "843343b9adc84d949f839d51814d55aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d9e5b3a1e144e6b34a55ab5cbce43f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a818afa6bb4f43c8b7e32a3c04f17211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b93060412f54083b6dd7b9203ae55d0",
      "max": 19579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_843343b9adc84d949f839d51814d55aa",
      "value": 19579
     }
    },
    "b0dca775977048f38841afae3d906eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
